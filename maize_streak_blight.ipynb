{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Despite the fact that the agricultural sector is a national economic development priority in sub-Saharan Africa, crop pests and diseases have been the challenge affecting major food security crops like maize. \n",
    "Maize Leaf Blight, also known as Northern Corn Leaf Blight has become a menace in low land agro-ecologies, during the last decade. On the other hand, according to research, Maize Streak Disease which is caused by the Maize Streak Virus is regarded as the third most serious disease affecting maize in sub-Saharan Africa. \n",
    "The prominence of these diseases has greatly affected the yields of Africaâ€™s most important food crop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <div style=\"text-align: center; margin-right: 20px;\">\n",
    "        <p>Healthy</p>\n",
    "        <img src=\"sample/1621590060253.jpg\" alt=\"Image 1\" style=\"width: 200;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p>Maize Leaf Blight</p>\n",
    "        <img src=\"sample/1621319276554.jpg\" alt=\"Image 2\" style=\"width: 200;\">\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "params = {\n",
    "    \"LEARNING_RATE\": 0.01,\n",
    "    \"CLASSES\": 2,\n",
    "    \"EPOCHS\": 2,\n",
    "    \"INCLUDE_TOP\": False,\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"WEIGHTS\": \"imagenet\",\n",
    "    \"IMAGE_SIZE\": [224, 224, 3],\n",
    "    \"DECAY\": 1e-6,\n",
    "    \"MOMENTUM\": 0.9\n",
    "}\n",
    "\n",
    "# mlflow configs\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/kalema3502/vggnet-transfer-learning-for-msv.mlflow\"\n",
    "MLFLOW_TRACKING_USERNAME = \"kalema3502\"\n",
    "MLFLOW_TRACKING_PASSWORD = \"fb3845efcc3b2e46a4157b1d2c977a21e02dd16e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "DATA = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "base_model = VGG16(input_shape=params['IMAGE_SIZE'], weights=params['WEIGHTS'], include_top=params['INCLUDE_TOP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# base model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze hidden layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom output(dense) layer\n",
    "output = Dense(params['CLASSES'], activation=\"softmax\") (Flatten() (base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# custom model\n",
    "new_model = Model(inputs=base_model.input, outputs=output)\n",
    "new_model.compile(\n",
    "            optimizer=optimizers.SGD(learning_rate=params['LEARNING_RATE'], decay=params['DECAY'], momentum=params['MOMENTUM']),\n",
    "            loss=keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "datagenerator_kwargs = dict(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "dataflow_kwargs = dict(\n",
    "            target_size=params['IMAGE_SIZE'][:-1],\n",
    "            batch_size=params['BATCH_SIZE'],\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "train_datagenerator = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=20,\n",
    "                height_shift_range=20,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "validation_datagenerator = ImageDataGenerator(\n",
    "               **datagenerator_kwargs\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train test sets\n",
    "train_set = train_datagenerator.flow_from_directory(\n",
    "            directory=DATA,\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            class_mode=\"categorical\",\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "validation_set = validation_datagenerator.flow_from_directory(\n",
    "            directory=DATA,\n",
    "            subset='validation',\n",
    "            shuffle=True,\n",
    "            class_mode=\"categorical\",\n",
    "            **dataflow_kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71642/3648385454.py:22: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  new_model.fit_generator(generator=train_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 00:59:55.439665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 3.7650 - accuracy: 0.7937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 01:07:32.107687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.04206, saving model to artifacts/model.h5\n",
      "60/60 [==============================] - 566s 9s/step - loss: 3.7650 - accuracy: 0.7937 - val_loss: 1.0421 - val_accuracy: 0.9125 - lr: 0.0100\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - ETA: 0s - loss: 3.3932 - accuracy: 0.8552\n",
      "Epoch 2: val_loss did not improve from 1.04206\n",
      "60/60 [==============================] - 566s 9s/step - loss: 3.3932 - accuracy: 0.8552 - val_loss: 1.1602 - val_accuracy: 0.9250 - lr: 0.0100\n",
      "Training completed in time: 0:19:49.024633\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "os.makedirs('artifacts/', exist_ok=True)\n",
    "\n",
    "steps_per_epoch = train_set.samples // train_set.batch_size\n",
    "validation_steps = validation_set.samples // validation_set.batch_size\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-5)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='artifacts/model.h5',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer]\n",
    "start = datetime.now()\n",
    "\n",
    "new_model.fit_generator(generator=train_set,\n",
    "                        validation_data=validation_set,\n",
    "                        epochs=params['EPOCHS'],\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_steps=validation_steps,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f\"Training completed in time: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 01:22:26.898781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 107s 7s/step - loss: 1.0421 - accuracy: 0.9125\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "best_model = load_model('artifacts/model.h5')\n",
    "\n",
    "results = best_model.evaluate(validation_set)\n",
    "\n",
    "scores = {'loss': results[0], 'accuracy': results[1]}\n",
    "\n",
    "try:\n",
    "    with open('scores.json', 'w') as json_file:\n",
    "        json.dump(scores, json_file)\n",
    "except IOError as e:\n",
    "    raise IOError(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow configs\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]= MLFLOW_TRACKING_URI\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]= MLFLOW_TRACKING_USERNAME\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]= MLFLOW_TRACKING_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/25 01:25:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb2pej9j2/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpb2pej9j2/model/data/model/assets\n",
      "/home/kalema/anaconda3/envs/kidney/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'VGG16Model'.\n",
      "2024/04/25 01:27:03 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: VGG16Model, version 1\n",
      "Created version '1' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "# experiment tracking\n",
    "mlflow.set_registry_uri(MLFLOW_TRACKING_URI)\n",
    "tracking_url_type_store= urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(\n",
    "        {\"loss\": results[0], \"accuracy\": results[1]}\n",
    "    )\n",
    "    \n",
    "    if tracking_url_type_store != \"file\":\n",
    "        mlflow.keras.log_model(best_model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "    else:\n",
    "        mlflow.keras.log_model(best_model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
