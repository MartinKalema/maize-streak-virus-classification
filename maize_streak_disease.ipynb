{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Despite the fact that the agricultural sector is a national economic development priority in sub-Saharan Africa, crop pests and diseases have been the challenge affecting major food security crops like maize. \n",
    "Maize Leaf Blight, also known as Northern Corn Leaf Blight has become a menace in low land agro-ecologies, during the last decade. On the other hand, according to research, Maize Streak Disease which is caused by the Maize Streak Virus is regarded as the third most serious disease affecting maize in sub-Saharan Africa. \n",
    "The prominence of these diseases has greatly affected the yields of Africaâ€™s most important food crop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <div style=\"text-align: center; margin-right: 20px;\">\n",
    "        <p>Healthy</p>\n",
    "        <img src=\"sample/1621590060253.jpg\" alt=\"Image 1\" style=\"width: 200;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p>Maize Streak Disease</p>\n",
    "        <img src=\"sample/1621319276554.jpg\" alt=\"Image 2\" style=\"width: 200;\">\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "params = {\n",
    "    \"LEARNING_RATE\": 0.01,\n",
    "    \"CLASSES\": 2,\n",
    "    \"EPOCHS\": 8,\n",
    "    \"INCLUDE_TOP\": False,\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"WEIGHTS\": \"imagenet\",\n",
    "    \"IMAGE_SIZE\": [224, 224, 3],\n",
    "    \"DECAY\": 1e-6,\n",
    "    \"MOMENTUM\": 0.9\n",
    "}\n",
    "\n",
    "# mlflow configs\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/kalema3502/vggnet-transfer-learning-for-msv.mlflow\"\n",
    "MLFLOW_TRACKING_USERNAME = \"kalema3502\"\n",
    "MLFLOW_TRACKING_PASSWORD = \"fb3845efcc3b2e46a4157b1d2c977a21e02dd16e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "DATA = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "base_model = VGG16(input_shape=params['IMAGE_SIZE'], weights=params['WEIGHTS'], include_top=params['INCLUDE_TOP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# base model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze hidden layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom output(dense) layer\n",
    "output = Dense(params['CLASSES'], activation=\"softmax\") (Flatten() (base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# custom model\n",
    "new_model = Model(inputs=base_model.input, outputs=output)\n",
    "new_model.compile(\n",
    "            optimizer=optimizers.SGD(learning_rate=params['LEARNING_RATE'], decay=params['DECAY'], momentum=params['MOMENTUM']),\n",
    "            loss=keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "datagenerator_kwargs = dict(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "dataflow_kwargs = dict(\n",
    "            target_size=params['IMAGE_SIZE'][:-1],\n",
    "            batch_size=params['BATCH_SIZE'],\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "train_datagenerator = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=20,\n",
    "                height_shift_range=20,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "validation_datagenerator = ImageDataGenerator(\n",
    "               **datagenerator_kwargs\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train test sets\n",
    "train_set = train_datagenerator.flow_from_directory(\n",
    "            directory=DATA,\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            class_mode=\"categorical\",\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "validation_set = validation_datagenerator.flow_from_directory(\n",
    "            directory=DATA,\n",
    "            subset='validation',\n",
    "            shuffle=True,\n",
    "            class_mode=\"categorical\",\n",
    "            **dataflow_kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6232/3648385454.py:22: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  new_model.fit_generator(generator=train_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 09:07:44.689819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-04-25 09:07:47.035976: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2024-04-25 09:07:47.475249: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2024-04-25 09:07:48.834124: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2024-04-25 09:07:48.953045: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2024-04-25 09:07:49.492470: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 12.2320 - accuracy: 0.7240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 09:15:10.988089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.51998, saving model to artifacts/model.h5\n",
      "60/60 [==============================] - 556s 9s/step - loss: 12.2320 - accuracy: 0.7240 - val_loss: 1.5200 - val_accuracy: 0.9458 - lr: 0.0100\n",
      "Epoch 2/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.8761 - accuracy: 0.8938\n",
      "Epoch 2: val_loss did not improve from 1.51998\n",
      "60/60 [==============================] - 537s 9s/step - loss: 2.8761 - accuracy: 0.8938 - val_loss: 1.7786 - val_accuracy: 0.9458 - lr: 0.0100\n",
      "Epoch 3/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 4.0008 - accuracy: 0.8802\n",
      "Epoch 3: val_loss did not improve from 1.51998\n",
      "60/60 [==============================] - 498s 8s/step - loss: 4.0008 - accuracy: 0.8802 - val_loss: 2.6783 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 4/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6523 - accuracy: 0.9333\n",
      "Epoch 4: val_loss did not improve from 1.51998\n",
      "60/60 [==============================] - 527s 9s/step - loss: 1.6523 - accuracy: 0.9333 - val_loss: 2.1126 - val_accuracy: 0.9125 - lr: 0.0100\n",
      "Epoch 5/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.1204 - accuracy: 0.9271\n",
      "Epoch 5: val_loss improved from 1.51998 to 1.48110, saving model to artifacts/model.h5\n",
      "60/60 [==============================] - 553s 9s/step - loss: 2.1204 - accuracy: 0.9271 - val_loss: 1.4811 - val_accuracy: 0.9500 - lr: 0.0100\n",
      "Epoch 6/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0228 - accuracy: 0.9302 \n",
      "Epoch 6: val_loss did not improve from 1.48110\n",
      "60/60 [==============================] - 2965s 50s/step - loss: 2.0228 - accuracy: 0.9302 - val_loss: 11.2395 - val_accuracy: 0.7042 - lr: 0.0100\n",
      "Epoch 7/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 4.0852 - accuracy: 0.8771\n",
      "Epoch 7: val_loss improved from 1.48110 to 1.25932, saving model to artifacts/model.h5\n",
      "60/60 [==============================] - 531s 9s/step - loss: 4.0852 - accuracy: 0.8771 - val_loss: 1.2593 - val_accuracy: 0.9542 - lr: 0.0100\n",
      "Epoch 8/8\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5744 - accuracy: 0.9521\n",
      "Epoch 8: val_loss did not improve from 1.25932\n",
      "60/60 [==============================] - 529s 9s/step - loss: 1.5744 - accuracy: 0.9521 - val_loss: 1.6235 - val_accuracy: 0.9417 - lr: 0.0100\n",
      "Training completed in time: 1:52:42.307205\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "os.makedirs('artifacts/', exist_ok=True)\n",
    "\n",
    "steps_per_epoch = train_set.samples // train_set.batch_size\n",
    "validation_steps = validation_set.samples // validation_set.batch_size\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-5)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='artifacts/model.h5',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer]\n",
    "start = datetime.now()\n",
    "\n",
    "new_model.fit_generator(generator=train_set,\n",
    "                        validation_data=validation_set,\n",
    "                        epochs=params['EPOCHS'],\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_steps=validation_steps,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f\"Training completed in time: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 12:10:40.221375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-04-25 12:10:41.138712: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2024-04-25 12:10:41.441395: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2024-04-25 12:10:42.631832: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2024-04-25 12:10:43.170877: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 102760448 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 1:58 - loss: 6.1094e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 12:10:48.655310: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 111s 7s/step - loss: 1.2593 - accuracy: 0.9542\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "best_model = load_model('artifacts/model.h5')\n",
    "\n",
    "results = best_model.evaluate(validation_set)\n",
    "\n",
    "scores = {'loss': results[0], 'accuracy': results[1]}\n",
    "\n",
    "try:\n",
    "    with open('scores.json', 'w') as json_file:\n",
    "        json.dump(scores, json_file)\n",
    "except IOError as e:\n",
    "    raise IOError(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow configs\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]= MLFLOW_TRACKING_URI\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]= MLFLOW_TRACKING_USERNAME\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]= MLFLOW_TRACKING_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/25 11:05:06 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe20yp8i3/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe20yp8i3/model/data/model/assets\n",
      "/home/kalema/anaconda3/envs/kidney/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2024/04/25 11:07:02 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: VGG16Model, version 2\n",
      "Created version '2' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "# experiment tracking\n",
    "mlflow.set_registry_uri(MLFLOW_TRACKING_URI)\n",
    "tracking_url_type_store= urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(\n",
    "        {\"loss\": results[0], \"accuracy\": results[1]}\n",
    "    )\n",
    "    \n",
    "    if tracking_url_type_store != \"file\":\n",
    "        mlflow.keras.log_model(best_model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "    else:\n",
    "        mlflow.keras.log_model(best_model, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
